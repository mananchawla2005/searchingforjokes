# ASSIGNMENT FOR RESEARCH INTERNSHIP at LOSSFUNK

## Generating the funniest joke imaginable with LLMs

- **Q1 Why did you pick the particular project?**

Ans: I picked this project because I resonanted with the problem. I have seen the problem in the past. LLMs struggle with generating good jokes which are funny. Till date nothing generated has made me laugh. When I read the attached paper, I was greatly impressed and did an effort to replicate the same in terms of joke, comedy and humor generation.

- **Q2 If you had more compute/time, what would you have done?**

Ans: Unfortunately my exams are going on as of attempting this challenge and I was only able to give it a day. I would have tried to use local inference instead of api inference to iterate faster. Moreover if I had more time and compute I would want to extend this idea to training llms with idea generation and then final solution generation methodology because as written in the paper, it could be a massive boost and we could condense pass@200 information in just a single pass using Reinforcement Learning.
Moreover I would love to perform ablations with this strategy for joke generation, creative writing, and various other non verifiable tasks using different models. One more idea could be posing this task as completition rather than question answer so that base models can be used as dicussed in the PLANSEARCH paper.
I would have also used MCTS to prune the search space as discussed in the paper and would have used KL divergence for the distribution of the baseline model vs plansearch to show if is there a huge difference between the two at pass 200. 
- **Q3 What did you learn in the project?**

Ans: When implementing the paper and using llm as a judge I learnt about strategies in which an llm can best perfom a judge. I used some of my own hypothesis like using A DEEP RESEARCH report on writing comedy and giving that knowledge to the verifier so that it can better judge the generated jokes. Also learning about how to increase diversity in response generation in instruction tuned LLMs and future directions to embed this into the model itself! Such a great idea! 

- **Q4 What surprised you the most?**

Ans: What suprised me the most is that *LLMS can be funny* I mean not completely as humans are but they can misdirect and adapt from real world references to right a joke. I was honestly not expecting that. Most I thought they would generate something which is different than what they usually generate but still memorizble and abdundant in the training data.
To my suprise this is so not the case. Adding a joke about management for a penguin? That was impressive to me.  LLms are far more powerful than we think they are. We just need to explore that search space and widen it in an efficient manner as much as we can. They generate a very funny standup comedy, humorous script which is full of jokes and misdirections. It takes the reader to suprise.

- **Q5 If you had to write a paper on the project, what else needs to be done?**

Ans: To write a paper on the topic, we need to perform ablations and try to show distributions between base model and the plan search technique. Also these prompts can be automated using LLMs so it can become a generalizable agent. For better speed, we should work on training a model using reinforcement learning. This can be a new technique to train reasoning models upon.
Also I would want to explore another level of top level abstraction other than idea space to start from as it can lead to much better results.

- **Q6 What's novelty in any case? What if LLMs are just memorizing? How would you test it?**

Ans: Novelty is a system's ability to keep creating things that the observer didn't predict (https://arxiv.org/abs/2406.04268) (in this case to baseline model) or something which is not obvious more like generalization which is different from memorization. For that we can do a test on the distribution of all kinds of generations by the two techniques. I would test it using KL divergence between the disribution of the probabilities of the tokens generated and that with plan search. Then I would take the KL Divergence between the two. This can show how much model is suprised from the output generated by plan search technique.
In heuristic analysis (by humans) memorization shouldnt lead to generalization among unrelated concepts like we see in case of penguin vs management. 


Note: I used gemma model for generation and verification as in this paper https://aclanthology.org/2025.cmcl-1.6.pdf , They show that they are the best class of models when come for standup comedy, joke and humor generation.
Also using deep research report for verification was partly inspired by https://freedium.cfd/https://medium.com/the-generator/how-i-built-funnygpt-an-ai-model-that-writes-standup-comedy-462e4485fd93

# To run
Add BASE_URL environment variable. The api follows openai compatible api.


# Appendix (Results)

- TOPIC: penguin

- BEST JOKE: You ever think about how penguins are just birds that gave up on their one job? Like, technically birds, right? But they just…didn’t bother. “Penguins are essentially birds that evolved to be terrible at their one defining trait: flying.” It’s like getting mad at a fish for not being able to do taxes. It’s just…not their skillset. We’re the ones projecting!\n\nBut they didn’t just give up. They doubled down on not flying. They became masters of waddling, experts in sliding on their bellies. It’s…impressive, in a deeply unsettling way. And then they built a whole society around it.\n\nBecause “Penguins are the ultimate corporate team players – They thrive in harsh conditions by huddling together for warmth, essentially turning teamwork into a survival strategy. It’s like they’re the middle managers of the animal kingdom: always in formation, never breaking rank.” I’m telling you, penguin society is brutal. They have mandatory 'Huddle Time' every two hours. If you’re not sufficiently close to your colleagues, HR will issue a 'Chill Deficiency Warning'. And the performance reviews? All based on how well you maintain body temperature. It’s a nightmare.\n\nYou know what the ultimate punishment is in penguin corporate? They make you lead the 'Flight Initiative'. It’s a completely pointless committee dedicated to brainstorming ways to fly. Years of wasted time, endless powerpoint presentations…it’s basically any tech company. \n\n(Pauses, looks thoughtful)\n\nHonestly, looking at penguins, I’m starting to think maybe giving up on your dreams isn’t so bad. I mean, at least they’re warm.